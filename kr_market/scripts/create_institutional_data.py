#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì™¸ì¸/ê¸°ê´€ ìˆœë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘
ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§ì„ í†µí•œ ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
Based on BLUEPRINT_09_SUPPORTING_MODULES.md
"""
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import os
from datetime import datetime


def scrape_institutional_data(ticker, max_retries=3):
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì™¸ì¸/ê¸°ê´€ ìˆœë§¤ë§¤ ë°ì´í„° í¬ë¡¤ë§
    
    Args:
        ticker: 6ìë¦¬ ì¢…ëª© ì½”ë“œ
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    Returns:
        Dict with 5d/10d/20d/60d net buy data
    """
    url = f"https://finance.naver.com/item/frgn.naver?code={ticker}"
    
    for attempt in range(max_retries):
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.encoding = 'euc-kr'
            
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # í…Œì´ë¸” íŒŒì‹±
            table = soup.find('table', {'class': 'type2'})
            if not table:
                return None
            
            rows = table.find_all('tr')
            
            # ë°ì´í„° ì¶”ì¶œ
            daily_data = []
            for row in rows[2:]:  # í—¤ë” ìŠ¤í‚µ
                cols = row.find_all('td')
                if len(cols) >= 7:
                    try:
                        # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜, ê¸°ê´€ ìˆœë§¤ìˆ˜ (ë‹¨ìœ„: ì£¼)
                        foreign_net = int(cols[5].get_text().strip().replace(',', '') or 0)
                        inst_net = int(cols[6].get_text().strip().replace(',', '') or 0)
                        
                        daily_data.append({
                            'foreign': foreign_net,
                            'inst': inst_net
                        })
                    except:
                        continue
            
            if len(daily_data) < 5:
                return None
            
            # ëˆ„ì  ê³„ì‚°
            foreign_5d = sum([d['foreign'] for d in daily_data[:5]])
            foreign_10d = sum([d['foreign'] for d in daily_data[:10]])
            foreign_20d = sum([d['foreign'] for d in daily_data[:20]])
            foreign_60d = sum([d['foreign'] for d in daily_data[:min(60, len(daily_data))]])
            
            inst_5d = sum([d['inst'] for d in daily_data[:5]])
            inst_10d = sum([d['inst'] for d in daily_data[:10]])
            inst_20d = sum([d['inst'] for d in daily_data[:20]])
            inst_60d = sum([d['inst'] for d in daily_data[:min(60, len(daily_data))]])
            
            # Supply Demand Index ê°„ë‹¨ ê³„ì‚° (0-100)
            # ì™¸ì¸ 50ì  + ê¸°ê´€ 50ì 
            foreign_score = min(max((foreign_60d / 1_000_000) * 10, 0), 50)
            inst_score = min(max((inst_60d / 500_000) * 10, 0), 50)
            supply_demand_index = min(foreign_score + inst_score, 100)
            
            return {
                'ticker': ticker,
                'scrape_date': datetime.now().strftime('%Y-%m-%d'),
                'foreign_net_buy_5d': foreign_5d,
                'foreign_net_buy_10d': foreign_10d,
                'foreign_net_buy_20d': foreign_20d,
                'foreign_net_buy_60d': foreign_60d,
                'institutional_net_buy_5d': inst_5d,
                'institutional_net_buy_10d': inst_10d,
                'institutional_net_buy_20d': inst_20d,
                'institutional_net_buy_60d': inst_60d,
                'supply_demand_index': round(supply_demand_index, 1)
            }
            
        except Exception as e:
            if attempt == max_retries - 1:
                return None
            time.sleep(1)
    
    return None


def create_institutional_data():
    """ì™¸ì¸/ê¸°ê´€ ìˆ˜ê¸‰ ë°ì´í„° ì „ì²´ ìˆ˜ì§‘"""
    print("ğŸ“Š ì™¸ì¸/ê¸°ê´€ ìˆœë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
    stocks_path = 'kr_market/data/stock_list.csv'
    if not os.path.exists(stocks_path):
        print("âŒ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. create_stock_list.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    stocks_df = pd.read_csv(stocks_path, encoding='utf-8-sig')
    tickers = stocks_df['ticker'].tolist()
    
    print(f"   ëŒ€ìƒ ì¢…ëª©: {len(tickers):,}ê°œ")
    print("   â³ ì•½ 10-15ë¶„ ì†Œìš” ì˜ˆìƒ...")
    
    # ë°ì´í„° ìˆ˜ì§‘
    results = []
    success_count = 0
    
    for i, ticker in enumerate(tickers):
        data = scrape_institutional_data(ticker)
        
        if data:
            # ì¢…ëª©ëª… ì¶”ê°€
            name = stocks_df[stocks_df['ticker'] == ticker]['name'].values[0]
            data['name'] = name
            results.append(data)
            success_count += 1
        
        # Progress
        if (i + 1) % 50 == 0:
            print(f"   ì§„í–‰ë¥ : {i+1}/{len(tickers)} ({success_count}ê°œ ì„±ê³µ)")
        
        # Rate limiting (ë„¤ì´ë²„ ì„œë²„ ë¶€í•˜ ë°©ì§€)
        time.sleep(0.3)
    
    # ì €ì¥
    if results:
        df = pd.DataFrame(results)
        df = df[['ticker', 'name', 'scrape_date',
                 'foreign_net_buy_5d', 'foreign_net_buy_10d', 'foreign_net_buy_20d', 'foreign_net_buy_60d',
                 'institutional_net_buy_5d', 'institutional_net_buy_10d', 'institutional_net_buy_20d', 'institutional_net_buy_60d',
                 'supply_demand_index']]
        
        output_path = 'kr_market/all_institutional_trend_data.csv'
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… ìˆ˜ê¸‰ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"   ì„±ê³µ: {success_count}/{len(tickers)}ê°œ ì¢…ëª©")
        print(f"   ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        # í†µê³„
        strong_buy = len(df[df['supply_demand_index'] >= 70])
        print(f"   ê°•í•œ ë§¤ìˆ˜ì„¸ (SIâ‰¥70): {strong_buy}ê°œ")
    else:
        print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")


if __name__ == "__main__":
    create_institutional_data()
